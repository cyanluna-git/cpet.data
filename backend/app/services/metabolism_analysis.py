"""Metabolic Analysis Service - ëŒ€ì‚¬ ë°ì´í„° ë¶„ì„ íŒŒì´í”„ë¼ì¸

Power binning, LOESS smoothing, FatMax/Crossover ë§ˆì»¤ ê³„ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

Features:
- Configurable 10W Power Binning (Median/Mean/Trimmed Mean)
- LOESS smoothing with adjustable fraction
- Phase trimming (Rest/Warm-up/Recovery ì œì™¸)
- FatMax (Peak fat oxidation) + Zone (90% MFO) ê³„ì‚°
- Crossover Point (Fat = CHO intersection) ê³„ì‚°
"""

from dataclasses import dataclass, field
from typing import List, Optional, Tuple, Dict, Any, Literal
import math
import numpy as np
import pandas as pd
from scipy.interpolate import interp1d
from scipy.optimize import brentq
from scipy.stats import trim_mean

try:
    from statsmodels.nonparametric.smoothers_lowess import lowess

    HAS_STATSMODELS = True
except ImportError:
    HAS_STATSMODELS = False
    lowess = None


@dataclass
class ProcessedDataPoint:
    """ì²˜ë¦¬ëœ ë°ì´í„° í¬ì¸íŠ¸"""

    power: float
    fat_oxidation: Optional[float]
    cho_oxidation: Optional[float]
    count: Optional[int] = None  # binned data only
    vo2: Optional[float] = None  # optional VO2 for relative calculations
    rer: Optional[float] = None  # optional RER

    def to_dict(self) -> Dict[str, Any]:
        result = {
            "power": self.power,
            "fat_oxidation": self.fat_oxidation,
            "cho_oxidation": self.cho_oxidation,
            "count": self.count,
        }
        if self.vo2 is not None:
            result["vo2"] = self.vo2
        if self.rer is not None:
            result["rer"] = self.rer
        return result


@dataclass
class FatMaxMarker:
    """FatMax ë§ˆì»¤ ì •ë³´"""

    power: int  # FatMax ì§€ì  íŒŒì›Œ (W)
    mfo: float  # Maximum Fat Oxidation (g/min)
    zone_min: int  # FatMax zone í•˜í•œ (W)
    zone_max: int  # FatMax zone ìƒí•œ (W)

    def to_dict(self) -> Dict[str, Any]:
        return {
            "power": self.power,
            "mfo": round(self.mfo, 4),
            "zone_min": self.zone_min,
            "zone_max": self.zone_max,
        }


@dataclass
class CrossoverMarker:
    """Crossover ì§€ì  ë§ˆì»¤ ì •ë³´"""

    power: Optional[int]  # Crossover ì§€ì  íŒŒì›Œ (W), ì—†ìœ¼ë©´ None
    fat_value: Optional[float]  # êµì°¨ ì§€ì  FatOx ê°’
    cho_value: Optional[float]  # êµì°¨ ì§€ì  CHOOx ê°’

    def to_dict(self) -> Dict[str, Any]:
        return {
            "power": self.power,
            "fat_value": (
                round(self.fat_value, 4) if self.fat_value is not None else None
            ),
            "cho_value": (
                round(self.cho_value, 4) if self.cho_value is not None else None
            ),
        }


@dataclass
class MetabolicMarkers:
    """ëŒ€ì‚¬ ë§ˆì»¤ ì •ë³´"""

    fat_max: FatMaxMarker
    crossover: CrossoverMarker

    def to_dict(self) -> Dict[str, Any]:
        return {
            "fat_max": self.fat_max.to_dict(),
            "crossover": self.crossover.to_dict(),
        }


@dataclass
class ProcessedSeries:
    """ì²˜ë¦¬ëœ ì‹œê³„ì—´ ë°ì´í„°"""

    raw: List[ProcessedDataPoint]  # ì›ë³¸ ë°ì´í„°
    binned: List[ProcessedDataPoint]  # 10W êµ¬ê°„ í‰ê· /ì¤‘ì•™ê°’
    smoothed: List[ProcessedDataPoint]  # LOESS smoothed
    trend: List[ProcessedDataPoint] = field(default_factory=list)  # Polynomial fit

    def to_dict(self) -> Dict[str, Any]:
        result = {
            "raw": [p.to_dict() for p in self.raw],
            "binned": [p.to_dict() for p in self.binned],
            "smoothed": [p.to_dict() for p in self.smoothed],
        }
        if self.trend:
            result["trend"] = [p.to_dict() for p in self.trend]
        return result


@dataclass
class MetabolismAnalysisResult:
    """ëŒ€ì‚¬ ë¶„ì„ ê²°ê³¼"""

    processed_series: ProcessedSeries
    metabolic_markers: MetabolicMarkers
    warnings: List[str]

    def to_dict(self) -> Dict[str, Any]:
        return {
            "processed_series": self.processed_series.to_dict(),
            "metabolic_markers": self.metabolic_markers.to_dict(),
            "warnings": self.warnings,
        }


@dataclass
class AnalysisConfig:
    """ë¶„ì„ ì„¤ì • dataclass"""

    loess_frac: float = 0.25
    bin_size: int = 10
    aggregation_method: Literal["median", "mean", "trimmed_mean"] = "median"
    trimmed_mean_proportiontocut: float = 0.1  # trimmed_mean ì‚¬ìš©ì‹œ ì–‘ìª½ 10% ì ˆì‚­
    fatmax_zone_threshold: float = 0.90
    exclude_rest: bool = True
    exclude_warmup: bool = True
    exclude_recovery: bool = True
    min_power_threshold: Optional[int] = None  # e.g., 50W ë¯¸ë§Œ ì œì™¸
    max_power_threshold: Optional[int] = None  # e.g., 400W ì´ˆê³¼ ì œì™¸
    non_negative_constraint: bool = True  # ìŒìˆ˜ ê°’ 0ìœ¼ë¡œ í´ë¨í•‘
    # Initial hyperventilation filtering (RER spike at start)
    exclude_initial_hyperventilation: bool = True
    initial_time_threshold: float = 120.0  # seconds - first 2 minutes
    initial_power_threshold: int = 40  # watts - exclude low power data during startup

    def to_dict(self) -> Dict[str, Any]:
        return {
            "loess_frac": self.loess_frac,
            "bin_size": self.bin_size,
            "aggregation_method": self.aggregation_method,
            "fatmax_zone_threshold": self.fatmax_zone_threshold,
            "exclude_rest": self.exclude_rest,
            "exclude_warmup": self.exclude_warmup,
            "exclude_recovery": self.exclude_recovery,
            "min_power_threshold": self.min_power_threshold,
            "max_power_threshold": self.max_power_threshold,
            "non_negative_constraint": self.non_negative_constraint,
            "exclude_initial_hyperventilation": self.exclude_initial_hyperventilation,
            "initial_time_threshold": self.initial_time_threshold,
            "initial_power_threshold": self.initial_power_threshold,
        }


class MetabolismAnalyzer:
    """ëŒ€ì‚¬ ë°ì´í„° ë¶„ì„ê¸°

    Features:
    - Configurable power binning (5W~30W)
    - Multiple aggregation methods (median, mean, trimmed_mean)
    - LOESS smoothing with adjustable fraction
    - Phase trimming options
    - FatMax and Crossover calculation
    """

    def __init__(
        self,
        loess_frac: float = 0.25,
        bin_size: int = 10,
        use_median: bool = True,
        fatmax_zone_threshold: float = 0.90,
        config: Optional[AnalysisConfig] = None,
    ):
        """
        Args:
            loess_frac: LOESS smoothing fraction (0.1 ~ 0.5 ê¶Œì¥)
            bin_size: Power binning í¬ê¸° (W), 5~30W ë²”ìœ„
            use_median: Trueë©´ ì¤‘ì•™ê°’, Falseë©´ í‰ê·  ì‚¬ìš© (deprecated, use config)
            fatmax_zone_threshold: FatMax zone ì„ê³„ê°’ (MFOì˜ ë¹„ìœ¨)
            config: AnalysisConfig ê°ì²´ (ì œê³µì‹œ ë‹¤ë¥¸ íŒŒë¼ë¯¸í„° ë¬´ì‹œ)
        """
        if config:
            self.config = config
        else:
            self.config = AnalysisConfig(
                loess_frac=loess_frac,
                bin_size=max(5, min(30, bin_size)),  # 5~30W ë²”ìœ„ ì œí•œ
                aggregation_method="median" if use_median else "mean",
                fatmax_zone_threshold=fatmax_zone_threshold,
            )
        self.warnings: List[str] = []

    def analyze(self, breath_data: List[Any]) -> Optional[MetabolismAnalysisResult]:
        """
        í˜¸í¡ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì²˜ë¦¬ëœ ì‹œê³„ì—´ê³¼ ë§ˆì»¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

        Args:
            breath_data: BreathData ê°ì²´ ë¦¬ìŠ¤íŠ¸ (bike_power, fat_oxidation, cho_oxidation í•„ìˆ˜)

        Returns:
            MetabolismAnalysisResult ë˜ëŠ” None (ë°ì´í„° ë¶€ì¡± ì‹œ)
        """
        self.warnings = []

        # Phase trimming: êµ¬ê°„ë³„ ì œì™¸ ì˜µì…˜ ì ìš©
        filtered_data = self._apply_phase_trimming(breath_data)

        if len(filtered_data) < 10:
            self.warnings.append(
                f"Insufficient exercise data for analysis: {len(filtered_data)} points"
            )
            return None

        # 1. Raw ë°ì´í„° ì¶”ì¶œ
        raw_points = self._extract_raw_points(filtered_data)

        if len(raw_points) < 5:
            self.warnings.append("Insufficient raw data points after extraction")
            return None

        # 2. Power Binning
        binned_points = self._power_binning(raw_points)

        if len(binned_points) < 3:
            self.warnings.append("Insufficient binned data points")
            return None

        # 3. LOESS Smoothing
        smoothed_points = self._loess_smoothing(binned_points)

        # 4. Polynomial Trend Fit (binned ë°ì´í„°ì—ì„œ ì§ì ‘ ê³„ì‚°í•˜ì—¬ ê¹”ë”í•œ í¬ë¬¼ì„  ìƒì„±)
        trend_points = self._polynomial_fit(binned_points)

        # 5. FatMax & Zone ê³„ì‚°
        fatmax_marker = self._calculate_fatmax(smoothed_points)

        # 6. Crossover Point ê³„ì‚°
        crossover_marker = self._calculate_crossover(smoothed_points)

        return MetabolismAnalysisResult(
            processed_series=ProcessedSeries(
                raw=raw_points,
                binned=binned_points,
                smoothed=smoothed_points,
                trend=trend_points,
            ),
            metabolic_markers=MetabolicMarkers(
                fat_max=fatmax_marker, crossover=crossover_marker
            ),
            warnings=self.warnings,
        )

    def _apply_phase_trimming(self, breath_data: List[Any]) -> List[Any]:
        """Phase trimming ì ìš©: Rest, Warm-up, Recovery êµ¬ê°„ ì œì™¸"""
        filtered = []

        for bd in breath_data:
            # í•„ìˆ˜ í•„ë“œ ì²´í¬
            if (
                bd.bike_power is None
                or bd.fat_oxidation is None
                or bd.cho_oxidation is None
            ):
                continue

            # Initial hyperventilation filtering (RER spike at start)
            # Exclude data points where both time < threshold AND power < threshold
            if self.config.exclude_initial_hyperventilation:
                t_sec = getattr(bd, "t_sec", None)
                if t_sec is not None and t_sec < self.config.initial_time_threshold:
                    if bd.bike_power < self.config.initial_power_threshold:
                        continue

            phase = getattr(bd, "phase", None) or ""

            # Phase ê¸°ë°˜ í•„í„°ë§
            if self.config.exclude_rest and phase.lower() in ("rest", "resting"):
                continue
            if self.config.exclude_warmup and phase.lower() in (
                "warmup",
                "warm-up",
                "warm_up",
            ):
                continue
            if self.config.exclude_recovery and phase.lower() in (
                "recovery",
                "cooldown",
                "cool-down",
            ):
                continue

            # Exercise/Peak êµ¬ê°„ë§Œ í¬í•¨ (ê¸°ë³¸)
            if phase and phase not in ("Exercise", "Peak", "exercise", "peak", ""):
                continue

            # Power threshold í•„í„°ë§
            if self.config.min_power_threshold is not None:
                if bd.bike_power < self.config.min_power_threshold:
                    continue
            if self.config.max_power_threshold is not None:
                if bd.bike_power > self.config.max_power_threshold:
                    continue

            filtered.append(bd)

        return filtered

    def _extract_raw_points(self, breath_data: List[Any]) -> List[ProcessedDataPoint]:
        """í˜¸í¡ ë°ì´í„°ì—ì„œ raw í¬ì¸íŠ¸ ì¶”ì¶œ"""
        points = []
        for bd in breath_data:
            points.append(
                ProcessedDataPoint(
                    power=float(bd.bike_power),
                    fat_oxidation=float(bd.fat_oxidation) if bd.fat_oxidation else None,
                    cho_oxidation=float(bd.cho_oxidation) if bd.cho_oxidation else None,
                    rer=float(bd.rer) if bd.rer else None,
                    count=1,
                )
            )
        return points

    def _power_binning(
        self, raw_points: List[ProcessedDataPoint]
    ) -> List[ProcessedDataPoint]:
        """
        Power ë°ì´í„°ë¥¼ bin_size W ë‹¨ìœ„ë¡œ ê·¸ë£¹í™”í•˜ê³  ì¤‘ì•™ê°’/í‰ê·  ê³„ì‚°

        Args:
            raw_points: Raw ë°ì´í„° í¬ì¸íŠ¸ ë¦¬ìŠ¤íŠ¸

        Returns:
            Binned ë°ì´í„° í¬ì¸íŠ¸ ë¦¬ìŠ¤íŠ¸ (power ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬)
        """
        # DataFrameìœ¼ë¡œ ë³€í™˜
        df = pd.DataFrame(
            [
                {
                    "power": p.power,
                    "fat_oxidation": p.fat_oxidation,
                    "cho_oxidation": p.cho_oxidation,
                    "rer": p.rer,
                }
                for p in raw_points
            ]
        )

        # Power bin í• ë‹¹
        bin_size = self.config.bin_size
        df["power_bin"] = (df["power"] / bin_size).round() * bin_size

        # ì§‘ê³„ ë°©ë²•ì— ë”°ë¥¸ ê·¸ë£¹í™”
        agg_method = self.config.aggregation_method

        if agg_method == "median":
            agg_df = (
                df.groupby("power_bin")
                .agg(
                    {
                        "fat_oxidation": "median",
                        "cho_oxidation": "median",
                        "rer": "median",
                        "power": "count",
                    }
                )
                .reset_index()
            )
        elif agg_method == "mean":
            agg_df = (
                df.groupby("power_bin")
                .agg(
                    {
                        "fat_oxidation": "mean",
                        "cho_oxidation": "mean",
                        "rer": "mean",
                        "power": "count",
                    }
                )
                .reset_index()
            )
        elif agg_method == "trimmed_mean":
            # Trimmed mean: ì–‘ìª½ 10% ì œê±° í›„ í‰ê· 
            proportiontocut = self.config.trimmed_mean_proportiontocut

            def safe_trim_mean(x):
                if len(x) < 4:  # ë°ì´í„°ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ì¼ë°˜ í‰ê· 
                    return x.mean()
                return trim_mean(x, proportiontocut)

            agg_df = (
                df.groupby("power_bin")
                .agg(
                    {
                        "fat_oxidation": safe_trim_mean,
                        "cho_oxidation": safe_trim_mean,
                        "rer": safe_trim_mean,
                        "power": "count",
                    }
                )
                .reset_index()
            )
        else:
            # ê¸°ë³¸ê°’: median
            agg_df = (
                df.groupby("power_bin")
                .agg(
                    {
                        "fat_oxidation": "median",
                        "cho_oxidation": "median",
                        "rer": "median",
                        "power": "count",
                    }
                )
                .reset_index()
            )

        agg_df = agg_df.rename(columns={"power": "count"})
        agg_df = agg_df.sort_values("power_bin").reset_index(drop=True)

        # ê²°ê³¼ ë³€í™˜
        binned_points = []
        for _, row in agg_df.iterrows():
            fat_ox = (
                float(row["fat_oxidation"]) if pd.notna(row["fat_oxidation"]) else None
            )
            cho_ox = (
                float(row["cho_oxidation"]) if pd.notna(row["cho_oxidation"]) else None
            )
            rer_val = float(row["rer"]) if pd.notna(row["rer"]) else None

            # Non-negative constraint
            if self.config.non_negative_constraint:
                if fat_ox is not None:
                    fat_ox = max(0.0, fat_ox)
                if cho_ox is not None:
                    cho_ox = max(0.0, cho_ox)

            binned_points.append(
                ProcessedDataPoint(
                    power=float(row["power_bin"]),
                    fat_oxidation=fat_ox,
                    cho_oxidation=cho_ox,
                    rer=rer_val,
                    count=int(row["count"]),
                )
            )

        return binned_points

    def _loess_smoothing(
        self, binned_points: List[ProcessedDataPoint]
    ) -> List[ProcessedDataPoint]:
        """
        LOESS (Locally Estimated Scatterplot Smoothing) ì ìš©

        Args:
            binned_points: Binned ë°ì´í„° í¬ì¸íŠ¸ ë¦¬ìŠ¤íŠ¸

        Returns:
            Smoothed ë°ì´í„° í¬ì¸íŠ¸ ë¦¬ìŠ¤íŠ¸
        """
        if not HAS_STATSMODELS:
            self.warnings.append(
                "statsmodels not available, using binned data as smoothed"
            )
            return binned_points

        if len(binned_points) < 4:
            self.warnings.append(
                "Not enough data points for LOESS smoothing, using binned data"
            )
            return binned_points

        # ë°ì´í„° ì¶”ì¶œ
        powers = np.array([p.power for p in binned_points])
        fat_ox = np.array(
            [
                p.fat_oxidation if p.fat_oxidation is not None else 0
                for p in binned_points
            ]
        )
        cho_ox = np.array(
            [
                p.cho_oxidation if p.cho_oxidation is not None else 0
                for p in binned_points
            ]
        )
        rer_vals = np.array(
            [p.rer if p.rer is not None else np.nan for p in binned_points]
        )

        # LOESS smoothing
        try:
            # frac ê°’ ì¡°ì • (ë°ì´í„° í¬ì¸íŠ¸ê°€ ì ì„ ê²½ìš°)
            frac = min(self.config.loess_frac, (len(powers) - 1) / len(powers))
            frac = max(frac, 0.15)  # ìµœì†Œ 0.15

            fat_smoothed = lowess(fat_ox, powers, frac=frac, return_sorted=True)
            cho_smoothed = lowess(cho_ox, powers, frac=frac, return_sorted=True)

            # RER smoothing (NaNì´ ì•„ë‹Œ ê°’ë“¤ë§Œ ì‚¬ìš©)
            rer_smoothed = None
            if not np.all(np.isnan(rer_vals)):
                valid_idx = ~np.isnan(rer_vals)
                if np.sum(valid_idx) >= 4:  # ìµœì†Œ 4ê°œ ì´ìƒì˜ ìœ íš¨ê°’ì´ ìˆì„ ë•Œë§Œ
                    rer_smoothed = lowess(
                        rer_vals[valid_idx],
                        powers[valid_idx],
                        frac=frac,
                        return_sorted=True,
                    )

            # ê²°ê³¼ ìƒì„± (ë¬¼ë¦¬ì  ì œì•½: >= 0)
            smoothed_points = []
            for i in range(len(fat_smoothed)):
                fat_val = float(fat_smoothed[i, 1])
                cho_val = float(cho_smoothed[i, 1])

                # RER ê°’ ë³´ê°„
                rer_val = None
                if rer_smoothed is not None:
                    power_val = fat_smoothed[i, 0]
                    # ê°€ì¥ ê°€ê¹Œìš´ power ê°’ì˜ RER ì‚¬ìš©
                    idx = np.argmin(np.abs(rer_smoothed[:, 0] - power_val))
                    rer_val = float(rer_smoothed[idx, 1])
                    # RER ë¬¼ë¦¬ì  ì œì•½ (0.7~1.2)
                    if not (0.5 <= rer_val <= 1.5):
                        rer_val = None

                # NaN ì²´í¬ ë° ì²˜ë¦¬
                if math.isnan(fat_val) or math.isinf(fat_val):
                    fat_val = 0.0
                if math.isnan(cho_val) or math.isinf(cho_val):
                    cho_val = 0.0

                # Non-negative constraint
                if self.config.non_negative_constraint:
                    fat_val = max(0.0, fat_val)
                    cho_val = max(0.0, cho_val)

                smoothed_points.append(
                    ProcessedDataPoint(
                        power=float(fat_smoothed[i, 0]),
                        fat_oxidation=fat_val,
                        cho_oxidation=cho_val,
                        rer=rer_val,
                        count=None,
                    )
                )

            return smoothed_points

        except Exception as e:
            self.warnings.append(f"LOESS smoothing failed: {str(e)}, using binned data")
            return binned_points

    def _polynomial_fit(
        self, binned_points: List[ProcessedDataPoint]
    ) -> List[ProcessedDataPoint]:
        """
        Polynomial Regressionì„ ì‚¬ìš©í•œ Trend Line ê³„ì‚° (ê¹”ë”í•œ í¬ë¬¼ì„  ìƒì„±)

        Fat/CHO/RER: Degree 2 polynomial (ë‹¨ìˆœí•œ Uìí˜• í¬ë¬¼ì„ )
        
        Note: binned ë°ì´í„°ì—ì„œ ì§ì ‘ ê³„ì‚°í•˜ì—¬ smooth ë°ì´í„°ë³´ë‹¤ ë” ë‹¨ìˆœí•œ íŒ¨í„´ ìƒì„±

        Args:
            binned_points: Binned ë°ì´í„° í¬ì¸íŠ¸ ë¦¬ìŠ¤íŠ¸

        Returns:
            Trend ë°ì´í„° í¬ì¸íŠ¸ ë¦¬ìŠ¤íŠ¸ (10W ê°„ê²©)
        """
        if len(binned_points) < 4:
            self.warnings.append("Not enough data points for polynomial fit")
            print(f"âš ï¸ Polynomial fit skipped: only {len(binned_points)} points")
            return []

        try:
            print(
                f"ğŸ”¬ Starting polynomial fit with {len(binned_points)} binned points"
            )
            # ë°ì´í„° ì¶”ì¶œ
            powers = np.array([p.power for p in binned_points])
            fat_ox = np.array(
                [
                    p.fat_oxidation if p.fat_oxidation is not None else 0
                    for p in binned_points
                ]
            )
            cho_ox = np.array(
                [
                    p.cho_oxidation if p.cho_oxidation is not None else 0
                    for p in binned_points
                ]
            )
            rer_vals = np.array(
                [p.rer if p.rer is not None else np.nan for p in binned_points]
            )

            # Polynomial degree ê²°ì •
            # ì‚¬ìš©ìì˜ ìš”ì²­ì— ë”°ë¼ Fat/CHOëŠ” ê¹”ë”í•œ 2ì°¨ í¬ë¬¼ì„ ì„ ìœ„í•´ Degree 2ë¡œ ê³ ì •
            # RERë„ 2ì°¨ë¡œ ê³ ì •í•˜ì—¬ ë‹¨ìˆœí•œ íŠ¸ë Œë“œ ìƒì„±
            fat_cho_degree = 2
            rer_degree = 2  # 3ì°¨ì—ì„œ 2ì°¨ë¡œ ë³€ê²½

            # Polynomial fitting
            fat_coeffs = np.polyfit(powers, fat_ox, fat_cho_degree)
            cho_coeffs = np.polyfit(powers, cho_ox, fat_cho_degree)

            fat_poly = np.poly1d(fat_coeffs)
            cho_poly = np.poly1d(cho_coeffs)

            # RER fitting (NaNì´ ì•„ë‹Œ ê°’ë§Œ ì‚¬ìš©)
            rer_poly = None
            valid_rer_idx = ~np.isnan(rer_vals)
            if np.sum(valid_rer_idx) >= 4:
                rer_coeffs = np.polyfit(
                    powers[valid_rer_idx], rer_vals[valid_rer_idx], rer_degree
                )
                rer_poly = np.poly1d(rer_coeffs)

            # Trend í¬ì¸íŠ¸ ìƒì„± (10W ê°„ê²©ìœ¼ë¡œ ë¶€ë“œëŸ½ê³  ë‹¨ìˆœí•œ í¬ë¬¼ì„  ìƒì„±)
            power_min = int(np.floor(powers.min() / 10) * 10)
            power_max = int(np.ceil(powers.max() / 10) * 10)
            trend_powers = np.arange(power_min, power_max + 1, 10)

            trend_points = []
            for p in trend_powers:
                fat_val = float(fat_poly(p))
                cho_val = float(cho_poly(p))
                rer_val = None

                if rer_poly is not None:
                    rer_val = float(rer_poly(p))
                    # RER ë¬¼ë¦¬ì  ì œì•½ (0.5~1.5)
                    if not (0.5 <= rer_val <= 1.5):
                        rer_val = None

                # NaN/Inf ì²´í¬
                if math.isnan(fat_val) or math.isinf(fat_val):
                    fat_val = 0.0
                if math.isnan(cho_val) or math.isinf(cho_val):
                    cho_val = 0.0

                # Non-negative constraint
                if self.config.non_negative_constraint:
                    fat_val = max(0.0, fat_val)
                    cho_val = max(0.0, cho_val)

                trend_points.append(
                    ProcessedDataPoint(
                        power=float(p),
                        fat_oxidation=fat_val,
                        cho_oxidation=cho_val,
                        rer=rer_val,
                        count=None,
                    )
                )

            print(
                f"âœ… Polynomial fit complete: {len(trend_points)} trend points generated"
            )
            return trend_points

        except Exception as e:
            self.warnings.append(f"Polynomial fit failed: {str(e)}")
            print(f"âŒ Polynomial fit failed: {str(e)}")
            return []

    def _calculate_fatmax(
        self, smoothed_points: List[ProcessedDataPoint]
    ) -> FatMaxMarker:
        """
        FatMax (Maximum Fat Oxidation) ë° Zone ê³„ì‚°

        Args:
            smoothed_points: Smoothed ë°ì´í„° í¬ì¸íŠ¸ ë¦¬ìŠ¤íŠ¸

        Returns:
            FatMaxMarker
        """
        if not smoothed_points:
            return FatMaxMarker(power=0, mfo=0, zone_min=0, zone_max=0)

        # MFO (Maximum Fat Oxidation) ì°¾ê¸°
        max_fat = 0.0
        max_fat_power = 0.0
        for p in smoothed_points:
            if p.fat_oxidation is not None and p.fat_oxidation > max_fat:
                max_fat = p.fat_oxidation
                max_fat_power = p.power

        if max_fat == 0:
            return FatMaxMarker(power=0, mfo=0, zone_min=0, zone_max=0)

        # FatMax Zone ê³„ì‚° (MFOì˜ 90% ì´ìƒ ìœ ì§€ êµ¬ê°„)
        threshold = max_fat * self.config.fatmax_zone_threshold
        zone_powers = [
            p.power
            for p in smoothed_points
            if p.fat_oxidation is not None and p.fat_oxidation >= threshold
        ]

        if zone_powers:
            zone_min = min(zone_powers)
            zone_max = max(zone_powers)
        else:
            zone_min = max_fat_power
            zone_max = max_fat_power

        return FatMaxMarker(
            power=int(round(max_fat_power)),
            mfo=max_fat,
            zone_min=int(round(zone_min)),
            zone_max=int(round(zone_max)),
        )

    def _calculate_crossover(
        self, smoothed_points: List[ProcessedDataPoint]
    ) -> CrossoverMarker:
        """
        Crossover Point (FatOx = CHOOx ì§€ì ) ê³„ì‚°

        Args:
            smoothed_points: Smoothed ë°ì´í„° í¬ì¸íŠ¸ ë¦¬ìŠ¤íŠ¸

        Returns:
            CrossoverMarker
        """
        if len(smoothed_points) < 3:
            return CrossoverMarker(power=None, fat_value=None, cho_value=None)

        # ë°ì´í„° ì¶”ì¶œ
        powers = np.array([p.power for p in smoothed_points])
        fat_ox = np.array(
            [
                p.fat_oxidation if p.fat_oxidation is not None else 0
                for p in smoothed_points
            ]
        )
        cho_ox = np.array(
            [
                p.cho_oxidation if p.cho_oxidation is not None else 0
                for p in smoothed_points
            ]
        )

        # FatOx - CHOOx ì°¨ì´
        diff = fat_ox - cho_ox

        # ë¶€í˜¸ ë³€í™” ì§€ì  ì°¾ê¸° (ì–‘ â†’ ìŒ: Fat > CHO ì—ì„œ Fat < CHOë¡œ)
        sign_changes = []
        for i in range(len(diff) - 1):
            if diff[i] > 0 and diff[i + 1] <= 0:
                sign_changes.append(i)
            elif diff[i] >= 0 and diff[i + 1] < 0:
                sign_changes.append(i)

        if not sign_changes:
            # êµì°¨ì  ì—†ìŒ
            return CrossoverMarker(power=None, fat_value=None, cho_value=None)

        try:
            # ì²« ë²ˆì§¸ êµì°¨ì  ì‚¬ìš© (ì¼ë°˜ì ìœ¼ë¡œ ìš´ë™ ê°•ë„ê°€ ì¦ê°€í•˜ë©´ì„œ ì²« êµì°¨)
            idx = sign_changes[0]

            # ì„ í˜• ë³´ê°„ìœ¼ë¡œ ì •í™•í•œ êµì°¨ì  ê³„ì‚°
            # diff[idx] > 0, diff[idx+1] <= 0
            p1, p2 = powers[idx], powers[idx + 1]
            d1, d2 = diff[idx], diff[idx + 1]

            if d1 == d2:
                crossover_power = p1
            else:
                # ì„ í˜• ë³´ê°„: d1 + (d2 - d1) * t = 0 => t = -d1 / (d2 - d1)
                t = -d1 / (d2 - d1)
                crossover_power = p1 + t * (p2 - p1)

            # êµì°¨ì ì—ì„œì˜ Fat/CHO ê°’ ê³„ì‚° (ì„ í˜• ë³´ê°„)
            crossover_fat = fat_ox[idx] + t * (fat_ox[idx + 1] - fat_ox[idx])
            crossover_cho = cho_ox[idx] + t * (cho_ox[idx + 1] - cho_ox[idx])

            return CrossoverMarker(
                power=int(round(crossover_power)),
                fat_value=float(crossover_fat),
                cho_value=float(crossover_cho),
            )

        except Exception as e:
            self.warnings.append(f"Crossover calculation failed: {str(e)}")
            return CrossoverMarker(power=None, fat_value=None, cho_value=None)


def analyze_metabolism(
    breath_data: List[Any],
    loess_frac: float = 0.25,
    bin_size: int = 10,
    use_median: bool = True,
    aggregation_method: Optional[str] = None,
    exclude_rest: bool = True,
    exclude_warmup: bool = True,
    exclude_recovery: bool = True,
    min_power_threshold: Optional[int] = None,
    fatmax_zone_threshold: float = 0.90,
) -> Optional[MetabolismAnalysisResult]:
    """
    í˜¸í¡ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì²˜ë¦¬ëœ ì‹œê³„ì—´ê³¼ ë§ˆì»¤ë¥¼ ë°˜í™˜í•˜ëŠ” í¸ì˜ í•¨ìˆ˜

    Args:
        breath_data: BreathData ê°ì²´ ë¦¬ìŠ¤íŠ¸
        loess_frac: LOESS smoothing fraction (0.1~0.5, default: 0.25)
        bin_size: Power binning í¬ê¸° (W, default: 10)
        use_median: Trueë©´ ì¤‘ì•™ê°’, Falseë©´ í‰ê·  ì‚¬ìš© (deprecated)
        aggregation_method: ì§‘ê³„ ë°©ë²• ("median", "mean", "trimmed_mean")
        exclude_rest: Rest êµ¬ê°„ ì œì™¸ ì—¬ë¶€
        exclude_warmup: Warm-up êµ¬ê°„ ì œì™¸ ì—¬ë¶€
        exclude_recovery: Recovery êµ¬ê°„ ì œì™¸ ì—¬ë¶€
        min_power_threshold: ìµœì†Œ íŒŒì›Œ ì„ê³„ê°’ (e.g., 50W ë¯¸ë§Œ ì œì™¸)
        fatmax_zone_threshold: FatMax zone ì„ê³„ê°’ (MFOì˜ ë¹„ìœ¨)

    Returns:
        MetabolismAnalysisResult ë˜ëŠ” None
    """
    # aggregation_methodê°€ ì œê³µë˜ë©´ ìš°ì„ , ì•„ë‹ˆë©´ use_median ê¸°ë°˜
    if aggregation_method is None:
        aggregation_method = "median" if use_median else "mean"

    config = AnalysisConfig(
        loess_frac=loess_frac,
        bin_size=bin_size,
        aggregation_method=aggregation_method,
        fatmax_zone_threshold=fatmax_zone_threshold,
        exclude_rest=exclude_rest,
        exclude_warmup=exclude_warmup,
        exclude_recovery=exclude_recovery,
        min_power_threshold=min_power_threshold,
    )

    analyzer = MetabolismAnalyzer(config=config)
    return analyzer.analyze(breath_data)
