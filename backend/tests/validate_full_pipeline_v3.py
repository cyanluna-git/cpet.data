"""
ğŸ§ª CPET íŒŒì´í”„ë¼ì¸ ì •ë°€ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ v3.0

ê²€ì¦ ì „ëµ: "API ê²°ê³¼ë¥¼ ë¯¿ì§€ ì•Šê³ , Raw ë°ì´í„°ë¥¼ ë°›ì•„ ì§ì ‘ ê³„ì‚°í•´ì„œ ë¹„êµ"

ê²€ì¦ í•­ëª©:
1. ëŒ€ì‚¬ìœ¨ ê³„ì‚° ì •í™•ë„ (Frayn Formula Integrity)
2. Phase Detection Consistency
3. Power Binning Integrity (Cross-Check)
4. LOESS Smoothing Quality (Residual Analysis)
5. Trend Validity & Extrapolation Check
6. Edge Cases (RER Anomaly, Data Length)
"""
import requests
import pandas as pd
import numpy as np
from typing import Dict, Any
import os


# === ì„¤ì • ===
BASE_URL = os.getenv("VITE_API_URL", f"http://localhost:{os.getenv('BACKEND_PORT', '8100')}")
TEST_ID = "c91339b9-c0ce-434d-b4ad-3c77452ed928"
LOGIN_EMAIL = "gerald.park@cpet.com"
LOGIN_PASS = "cpet2026!"


def login() -> str:
    """ë¡œê·¸ì¸í•˜ì—¬ í† í° ë°˜í™˜"""
    res = requests.post(
        f"{BASE_URL}/api/auth/login",
        data={"username": LOGIN_EMAIL, "password": LOGIN_PASS}
    )
    if res.status_code != 200:
        raise Exception(f"Login failed: {res.status_code} - {res.text}")
    return res.json()["access_token"]


def print_section(title: str):
    """ì„¹ì…˜ í—¤ë” ì¶œë ¥"""
    print("\n" + "="*70)
    print(f"ğŸ” [{title}]")
    print("="*70)


def print_result(passed: bool, message: str, details: str = ""):
    """ê²€ì¦ ê²°ê³¼ ì¶œë ¥"""
    icon = "âœ… PASS" if passed else "âŒ FAIL"
    print(f"   {icon}: {message}")
    if details:
        print(f"      {details}")


def validate_frayn_formula(df_raw: pd.DataFrame) -> Dict[str, Any]:
    """1. Frayn ê³µì‹ ì •í™•ë„ ê²€ì¦"""
    print_section("Check 1: Metabolic Rate Calculation Integrity")
    
    # vo2, vco2ê°€ ì—†ìœ¼ë©´ ìŠ¤í‚µ
    if 'vo2' not in df_raw.columns or 'vco2' not in df_raw.columns:
        print_result(False, "vo2/vco2 columns not available in API response", "SKIP - Cannot verify Frayn formula")
        print("   âš ï¸ This means vo2/vco2 values are None in ProcessedDataPoint")
        print("   âš ï¸ Need to check why MetabolismAnalyzer._extract_raw_points() returns None for vo2/vco2")
        return {"passed": False, "reason": "no_vo2_vco2_columns", "skipped": True}
    
    # VO2, VCO2ê°€ ìˆëŠ” í–‰ë§Œ ì¶”ì¶œ
    valid_raw = df_raw.dropna(subset=['vo2', 'vco2', 'fat_oxidation']).copy()
    
    if valid_raw.empty:
        print_result(False, "No valid data with vo2/vco2/fat_oxidation")
        return {"passed": False, "reason": "no_data"}
    
    # Frayn ê³µì‹ìœ¼ë¡œ ì§ì ‘ ê³„ì‚° (mL/min -> L/min ë³€í™˜)
    calc_fat = (1.67 * valid_raw['vo2']/1000 - 1.67 * valid_raw['vco2']/1000).clip(lower=0)
    calc_cho = (4.55 * valid_raw['vco2']/1000 - 3.21 * valid_raw['vo2']/1000).clip(lower=0)
    
    # ì˜¤ì°¨ ê³„ì‚° (ì†Œìˆ˜ì  3ìë¦¬ í—ˆìš©: 0.005 g/min)
    fat_diff = np.abs(valid_raw['fat_oxidation'] - calc_fat)
    cho_diff = np.abs(valid_raw['cho_oxidation'] - calc_cho) if 'cho_oxidation' in valid_raw.columns else pd.Series()
    
    mismatch_count = (fat_diff > 0.005).sum()
    max_diff = fat_diff.max()
    mean_diff = fat_diff.mean()
    
    passed = mismatch_count == 0
    print_result(
        passed,
        f"DB stored oxidation rates match Frayn formula (N={len(valid_raw)})",
        f"Mismatches: {mismatch_count}, Max diff: {max_diff:.6f} g/min, Mean: {mean_diff:.6f} g/min"
    )
    
    return {
        "passed": passed,
        "total_points": len(valid_raw),
        "mismatches": int(mismatch_count),
        "max_diff": float(max_diff),
        "mean_diff": float(mean_diff)
    }


def validate_phase_detection(df_raw: pd.DataFrame) -> Dict[str, Any]:
    """2. Phase Detection ì¼ê´€ì„± ê²€ì¦"""
    print_section("Check 2: Phase Detection Consistency")
    
    if 'phase' not in df_raw.columns:
        print_result(False, "Phase column not found in raw data", "SKIP")
        return {"passed": True, "reason": "no_phase_column"}
    
    issues = []
    
    # Rest êµ¬ê°„ì¸ë° Powerê°€ ë†’ì€ ê²½ìš°
    rest_high_power = df_raw[(df_raw['phase'] == 'Rest') & (df_raw['power'] > 30)]
    if not rest_high_power.empty:
        issues.append(f"{len(rest_high_power)} Rest points with power > 30W")
    
    # Warmup êµ¬ê°„ì¸ë° Powerê°€ Rest ìˆ˜ì¤€ì¸ ê²½ìš°
    warmup_low_power = df_raw[(df_raw['phase'] == 'Warm-up') & (df_raw['power'] < 20)]
    if not warmup_low_power.empty:
        issues.append(f"{len(warmup_low_power)} Warm-up points with power < 20W")
    
    # Exercise êµ¬ê°„ì¸ë° Powerê°€ Warmup ìˆ˜ì¤€ì¸ ê²½ìš°
    exercise_low_power = df_raw[(df_raw['phase'] == 'Exercise') & (df_raw['power'] < 50)]
    if not exercise_low_power.empty:
        issues.append(f"{len(exercise_low_power)} Exercise points with power < 50W")
    
    passed = len(issues) == 0
    
    if passed:
        print_result(True, "Phase labels are consistent with power levels")
    else:
        print_result(False, "Phase labeling inconsistencies found", " | ".join(issues))
    
    # Phase transition ì ê²€
    phase_changes = []
    prev_phase = None
    for idx, row in df_raw.iterrows():
        if row['phase'] != prev_phase:
            phase_changes.append({
                'from': prev_phase,
                'to': row['phase'],
                'power': row['power']
            })
            prev_phase = row['phase']
    
    print(f"   Phase transitions: {len(phase_changes)}")
    for change in phase_changes[:3]:  # ì²˜ìŒ 3ê°œë§Œ í‘œì‹œ
        print(f"      {change['from']} â†’ {change['to']}: {change['power']:.0f}W")
    
    return {
        "passed": passed,
        "issues": issues,
        "transition_count": len(phase_changes)
    }


def validate_binning_integrity(df_raw: pd.DataFrame, df_binned: pd.DataFrame) -> Dict[str, Any]:
    """3. Power Binning ë¬´ê²°ì„± ê²€ì¦ (ì§ì ‘ ê³„ì‚°í•˜ì—¬ ë¹„êµ)"""
    print_section("Check 3: Power Binning Integrity (Cross-Check)")
    
    if df_binned.empty:
        print_result(False, "No binned data returned from API")
        return {"passed": False, "reason": "no_binned_data"}
    
    # ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì§ì ‘ Binning ìˆ˜í–‰ (10W ë‹¨ìœ„)
    df_raw_copy = df_raw.copy()
    df_raw_copy['bin'] = (df_raw_copy['power'] / 10).round() * 10
    
    # Median ì§‘ê³„
    manual_bin = df_raw_copy.groupby('bin').agg({
        'fat_oxidation': 'median',
        'cho_oxidation': 'median',
        'rer': 'median',
        'power': 'count'  # countë¡œ ê°œìˆ˜ í™•ì¸
    }).reset_index()
    manual_bin.rename(columns={'power': 'count'}, inplace=True)
    
    # API ê²°ê³¼ì™€ ë¹„êµ
    merged = pd.merge(
        manual_bin, 
        df_binned, 
        left_on='bin', 
        right_on='power', 
        suffixes=('_manual', '_api'),
        how='inner'
    )
    
    if merged.empty:
        print_result(False, "No matching bins between manual and API calculation")
        return {"passed": False, "reason": "no_match"}
    
    # Fat oxidation ë¹„êµ
    fat_diff = np.abs(merged['fat_oxidation_manual'] - merged['fat_oxidation_api'])
    max_diff = fat_diff.max()
    mean_diff = fat_diff.mean()
    
    # Count ë¹„êµ (ë°ì´í„° ì†ì‹¤ ì²´í¬)
    total_raw = len(df_raw_copy)
    total_binned_count = df_binned['count'].sum() if 'count' in df_binned.columns else len(df_binned)
    
    passed = max_diff < 0.01  # 0.01 g/min í—ˆìš© ì˜¤ì°¨
    
    print_result(
        passed,
        f"API Binning matches manual calculation (N={len(merged)} bins)",
        f"Max diff: {max_diff:.6f} g/min, Mean: {mean_diff:.6f} g/min"
    )
    
    # ë°ì´í„° ë³´ì¡´ìœ¨
    if 'count' in df_binned.columns:
        preservation_rate = (total_binned_count / total_raw * 100) if total_raw > 0 else 0
        print(f"   Data Preservation: {total_raw} raw â†’ {total_binned_count} binned ({preservation_rate:.1f}%)")
        
        if preservation_rate < 95:
            print(f"   âš ï¸ WARNING: {100-preservation_rate:.1f}% data loss during binning!")
    
    return {
        "passed": passed,
        "matched_bins": len(merged),
        "max_diff": float(max_diff),
        "mean_diff": float(mean_diff),
        "raw_count": total_raw,
        "binned_count": int(total_binned_count) if 'count' in df_binned.columns else len(df_binned)
    }


def validate_smoothing_quality(df_binned: pd.DataFrame, df_smooth: pd.DataFrame) -> Dict[str, Any]:
    """4. LOESS Smoothing í’ˆì§ˆ ê²€ì¦ (ì”ì°¨ ë¶„ì„)"""
    print_section("Check 4: LOESS Smoothing Quality (Residual Analysis)")
    
    if df_smooth.empty or df_binned.empty:
        print_result(False, "Missing binned or smoothed data", "SKIP")
        return {"passed": True, "reason": "no_data"}
    
    # Powerë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë§¤ì¹­ (Binnedì™€ SmoothedëŠ” ê°™ì€ Power í¬ì¸íŠ¸ë¥¼ ê°€ì§)
    merged = pd.merge(
        df_binned,
        df_smooth,
        on='power',
        suffixes=('_binned', '_smooth'),
        how='inner'
    )
    
    if merged.empty:
        print_result(False, "Cannot match binned and smoothed data")
        return {"passed": False, "reason": "no_match"}
    
    # Fat oxidation ì”ì°¨ ê³„ì‚°
    residuals = np.abs(merged['fat_oxidation_binned'] - merged['fat_oxidation_smooth'])
    mae = residuals.mean()
    max_residual = residuals.max()
    
    # í”¼í¬ ë³´ì¡´ìœ¨
    binned_max = merged['fat_oxidation_binned'].max()
    smooth_max = merged['fat_oxidation_smooth'].max()
    peak_preservation = (smooth_max / binned_max * 100) if binned_max > 0 else 0
    peak_loss = 100 - peak_preservation
    
    # ì„ê³„ê°’: MAE < 0.15 g/min, í”¼í¬ ì†ì‹¤ < 20%
    passed = mae < 0.15 and peak_loss < 20
    
    print_result(
        passed,
        f"Smoothing preserves data shape (N={len(merged)} points)",
        f"MAE: {mae:.4f} g/min, Max residual: {max_residual:.4f} g/min"
    )
    print(f"   Peak Preservation: {peak_preservation:.1f}% (Binned: {binned_max:.4f} â†’ Smooth: {smooth_max:.4f} g/min)")
    
    if not passed:
        if mae >= 0.15:
            print("   âš ï¸ WARNING: Smoothing is too aggressive (high MAE)")
        if peak_loss >= 20:
            print(f"   âš ï¸ WARNING: Excessive peak loss ({peak_loss:.1f}%)")
    
    return {
        "passed": passed,
        "mae": float(mae),
        "max_residual": float(max_residual),
        "peak_preservation_pct": float(peak_preservation),
        "peak_loss_pct": float(peak_loss)
    }


def validate_trend_extrapolation(df_raw: pd.DataFrame, df_trend: pd.DataFrame) -> Dict[str, Any]:
    """5. Trend Extrapolation ê²€ì¦"""
    print_section("Check 5: Trend Validity & Extrapolation Check")
    
    if df_trend.empty:
        print_result(False, "No trend data returned from API", "SKIP")
        return {"passed": True, "reason": "no_trend"}
    
    # Raw ë°ì´í„°ì˜ Power ë²”ìœ„
    min_raw_p = df_raw['power'].min()
    max_raw_p = df_raw['power'].max()
    
    # Trendê°€ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ëŠ” í¬ì¸íŠ¸ (Â±10W ì—¬ìœ )
    trend_out_of_bounds = df_trend[
        (df_trend['power'] < min_raw_p - 10) | 
        (df_trend['power'] > max_raw_p + 10)
    ]
    
    passed = trend_out_of_bounds.empty
    
    print_result(
        passed,
        f"Trend lines stay within valid power range ({min_raw_p:.0f}-{max_raw_p:.0f}W)",
        f"Trend range: {df_trend['power'].min():.0f}-{df_trend['power'].max():.0f}W, Out-of-bounds: {len(trend_out_of_bounds)} points"
    )
    
    if not passed:
        print(f"   âš ï¸ WARNING: Trend extrapolates beyond safe range!")
        print(f"      Extrapolated points: {list(trend_out_of_bounds['power'].values)}")
    
    return {
        "passed": passed,
        "raw_power_range": (float(min_raw_p), float(max_raw_p)),
        "trend_power_range": (float(df_trend['power'].min()), float(df_trend['power'].max())),
        "out_of_bounds_count": len(trend_out_of_bounds)
    }


def validate_edge_cases(df_raw: pd.DataFrame) -> Dict[str, Any]:
    """6. Edge Cases ê²€ì¦ (ë°ì´í„° í’ˆì§ˆ)"""
    print_section("Check 6: Edge Cases & Data Quality")
    
    results = []
    
    # 1. ë°ì´í„° ê¸¸ì´
    data_length = len(df_raw)
    if data_length < 50:
        results.append(("WARNING", f"Dataset is very short ({data_length} points). Results may be unstable."))
    else:
        results.append(("PASS", f"Sufficient data length ({data_length} points)"))
    
    # 2. RER ì´ìƒì¹˜ (ìƒë¦¬í•™ì ìœ¼ë¡œ ë¶ˆê°€ëŠ¥í•œ ê°’)
    if 'rer' in df_raw.columns:
        valid_rer = df_raw['rer'].dropna()
        abnormal_rer = valid_rer[(valid_rer < 0.65) | (valid_rer > 1.3)]
        abnormal_pct = (len(abnormal_rer) / len(valid_rer) * 100) if len(valid_rer) > 0 else 0
        
        if not abnormal_rer.empty:
            results.append(("WARNING", f"Found {len(abnormal_rer)} points ({abnormal_pct:.1f}%) with abnormal RER (<0.65 or >1.3)"))
            results.append(("INFO", "Likely sensor error or mask leak"))
        else:
            results.append(("PASS", "All RER values are within physiological limits (0.65-1.3)"))
    
    # 3. ê²°ì¸¡ê°’ ë¹„ìœ¨
    if 'vo2' in df_raw.columns:
        missing_vo2 = df_raw['vo2'].isna().sum()
        missing_vco2 = df_raw['vco2'].isna().sum() if 'vco2' in df_raw.columns else 0
        missing_pct = (missing_vo2 / len(df_raw) * 100) if len(df_raw) > 0 else 0
        
        if missing_pct > 30:
            results.append(("FAIL", f"Excessive missing VO2/VCO2 data ({missing_pct:.1f}%)"))
        elif missing_pct > 10:
            results.append(("WARNING", f"Moderate missing data ({missing_pct:.1f}%)"))
        else:
            results.append(("PASS", f"Low missing data rate ({missing_pct:.1f}%)"))
    else:
        results.append(("WARNING", "vo2/vco2 columns not in API response (all None)"))
    
    # 4. Power ë¶„í¬ (Ramp vs Step í”„ë¡œí† ì½œ ê°ì§€)
    if 'power' in df_raw.columns:
        power_std = df_raw['power'].std()
        power_range = df_raw['power'].max() - df_raw['power'].min()
        
        if power_std < 10 and power_range < 30:
            results.append(("INFO", "Steady-state protocol detected (constant power)"))
        else:
            results.append(("INFO", f"Incremental protocol (power range: {power_range:.0f}W, std: {power_std:.1f}W)"))
    
    # ê²°ê³¼ ì¶œë ¥
    for level, msg in results:
        if level == "PASS":
            print_result(True, msg)
        elif level == "FAIL":
            print_result(False, msg)
        else:  # WARNING or INFO
            print(f"   âš ï¸ {level}: {msg}")
    
    passed = all(level != "FAIL" for level, _ in results)
    
    return {
        "passed": passed,
        "data_length": data_length,
        "abnormal_rer_count": len(abnormal_rer) if 'rer' in df_raw.columns else 0,
        "missing_pct": float(missing_pct),
        "results": results
    }


def run_precision_validation():
    """ì „ì²´ ê²€ì¦ ì‹¤í–‰"""
    print("\n" + "ğŸš€ " + "="*66)
    print("ğŸš€ [CPET Pipeline Precision Validation v3.0]")
    print("ğŸš€ " + "="*66)
    print(f"\nğŸ“‹ Test ID: {TEST_ID}")
    print(f"ğŸ“‹ Endpoint: {BASE_URL}")
    print(f"ğŸ“‹ Strategy: Cross-check API results with direct calculation\n")
    
    all_results = {}
    
    try:
        # ë¡œê·¸ì¸
        print("ğŸ” Authenticating...")
        token = login()
        headers = {"Authorization": f"Bearer {token}"}
        print("âœ… Login successful\n")
        
        # API ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        print("ğŸ“¥ Fetching analysis data from API...")
        res = requests.get(
            f"{BASE_URL}/api/tests/{TEST_ID}/analysis",
            headers=headers,
            params={
                "include_processed": "true",
                "loess_frac": 0.25,
                "bin_size": 10,
                "aggregation_method": "median",
                "min_power_threshold": 0
            }
        )
        
        if res.status_code != 200:
            raise Exception(f"API request failed: {res.status_code} - {res.text}")
        
        data = res.json()
        series = data.get("processed_series", {})
        
        # DataFrame ë³€í™˜
        df_raw = pd.DataFrame(series.get('raw', []))
        df_binned = pd.DataFrame(series.get('binned', []))
        df_smooth = pd.DataFrame(series.get('smoothed', []))
        df_trend = pd.DataFrame(series.get('trend', []))
        
        print(f"âœ… Data loaded successfully")
        print(f"   Raw: {len(df_raw)}, Binned: {len(df_binned)}, Smooth: {len(df_smooth)}, Trend: {len(df_trend)}")
        
        # ë””ë²„ê¹…: ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ í™•ì¸
        print(f"\nğŸ“‹ Available columns in raw data:")
        print(f"   {', '.join(df_raw.columns.tolist())}\n")
        
        # ê²€ì¦ ìˆ˜í–‰
        all_results['frayn'] = validate_frayn_formula(df_raw)
        all_results['phase'] = validate_phase_detection(df_raw)
        all_results['binning'] = validate_binning_integrity(df_raw, df_binned)
        all_results['smoothing'] = validate_smoothing_quality(df_binned, df_smooth)
        all_results['trend'] = validate_trend_extrapolation(df_raw, df_trend)
        all_results['edge_cases'] = validate_edge_cases(df_raw)
        
        # ìµœì¢… ìš”ì•½
        print("\n" + "="*70)
        print("ğŸ“Š VALIDATION SUMMARY")
        print("="*70)
        
        checks = [
            ("1. Frayn Formula", all_results['frayn']['passed']),
            ("2. Phase Detection", all_results['phase']['passed']),
            ("3. Binning Integrity", all_results['binning']['passed']),
            ("4. Smoothing Quality", all_results['smoothing']['passed']),
            ("5. Trend Validity", all_results['trend']['passed']),
            ("6. Edge Cases", all_results['edge_cases']['passed'])
        ]
        
        passed_count = sum(1 for _, passed in checks if passed)
        total_count = len(checks)
        
        for name, passed in checks:
            icon = "âœ…" if passed else "âŒ"
            print(f"   {icon} {name}")
        
        print("\n" + "="*70)
        if passed_count == total_count:
            print("ğŸ‰ ALL CHECKS PASSED! Pipeline integrity verified.")
        else:
            print(f"âš ï¸  {passed_count}/{total_count} checks passed. Review failures above.")
        print("="*70 + "\n")
        
        return all_results
        
    except Exception as e:
        print(f"\nâŒ Validation System Error: {str(e)}")
        import traceback
        traceback.print_exc()
        return {"error": str(e)}


if __name__ == "__main__":
    results = run_precision_validation()
