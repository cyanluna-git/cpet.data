"""íŒŒë¼ë¯¸í„° ë¯¼ê°ë„ ë¶„ì„ (Parameter Sensitivity Analysis)

ëª©ì :
- LOESS fraction, bin size, aggregation method ë³€í™”ê°€ ê²°ê³¼ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ íŒŒì•…
- ìµœì  íŒŒë¼ë¯¸í„° ë²”ìœ„ ë„ì¶œ
- ê²°ê³¼ì˜ ì‹ ë¢°êµ¬ê°„ ì¸¡ì •
"""
import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

import asyncio
from uuid import UUID
from sqlalchemy import select
from sqlalchemy.orm import sessionmaker
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from app.models.breath_data import BreathData
from app.models.cpet_test import CPETTest
from app.core.config import settings
from app.services.metabolism_analysis import MetabolismAnalyzer
import numpy as np
import pandas as pd
from itertools import product

TEST_ID = "c91339b9-c0ce-434d-b4ad-3c77452ed928"  # Park Yongdoo


async def run_sensitivity_analysis():
    """íŒŒë¼ë¯¸í„° ì¡°í•©ë³„ ë¶„ì„ ì‹¤í–‰"""
    
    print("="*80)
    print("íŒŒë¼ë¯¸í„° ë¯¼ê°ë„ ë¶„ì„")
    print("="*80 + "\n")
    
    engine = create_async_engine(settings.DATABASE_URL, echo=False)
    async_session = sessionmaker(engine, class_=AsyncSession, expire_on_commit=False)
    
    async with async_session() as session:
        test_uuid = UUID(TEST_ID)
        
        # í…ŒìŠ¤íŠ¸ ë° ë°ì´í„° ë¡œë“œ
        test_query = select(CPETTest).where(CPETTest.test_id == test_uuid)
        test_result = await session.execute(test_query)
        test = test_result.scalar_one_or_none()
        
        if not test:
            print(f"âŒ í…ŒìŠ¤íŠ¸ ì—†ìŒ: {TEST_ID}")
            return
        
        print(f"ğŸ“‹ í…ŒìŠ¤íŠ¸: {TEST_ID}")
        print(f"   VO2MAX: {test.vo2_max:.0f} ml/min\n")
        
        # BreathData ì¡°íšŒ
        query = select(BreathData).where(
            BreathData.test_id == test_uuid
        ).order_by(BreathData.t_sec)
        
        result = await session.execute(query)
        breath_data = list(result.scalars().all())
        
        print(f"ì´ ë°ì´í„°: {len(breath_data)}ê°œ\n")
        
        # === íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì •ì˜ ===
        loess_fracs = [0.15, 0.2, 0.25, 0.3, 0.35, 0.5]
        bin_sizes = [5, 10, 15, 20]
        agg_methods = ['median', 'mean', 'trimmed_mean']
        
        # Baseline (ê¸°ì¤€ê°’)
        baseline = {
            'loess_frac': 0.25,
            'bin_size': 10,
            'agg_method': 'median'
        }
        
        print(f"ğŸ“Š ì´ í…ŒìŠ¤íŠ¸ ì¡°í•© ìˆ˜: {len(loess_fracs) * len(bin_sizes) * len(agg_methods)}")
        print(f"   Baseline: loess_frac={baseline['loess_frac']}, "
              f"bin_size={baseline['bin_size']}, agg={baseline['agg_method']}\n")
        
        results = []
        
        # === 1. LOESS Fraction ë¯¼ê°ë„ (bin_size=10, agg=median ê³ ì •) ===
        print("1ï¸âƒ£  LOESS Fraction ë¯¼ê°ë„ ë¶„ì„")
        print("-" * 80)
        print(f"{'LOESS Frac':<12} {'FatMax(W)':<12} {'MFO(g/min)':<12} {'RÂ²':<8} {'í”¼í¬ì†ì‹¤%':<10}")
        print("-" * 80)
        
        baseline_result = None
        
        for frac in loess_fracs:
            analyzer = MetabolismAnalyzer(
                loess_frac=frac,
                bin_size=baseline['bin_size'],
                use_median=(baseline['agg_method'] == 'median')
            )
            
            if baseline['agg_method'] != 'median':
                analyzer.config.aggregation_method = baseline['agg_method']
            
            analysis = analyzer.analyze(breath_data)
            
            if not analysis:
                print(f"{frac:<12.2f} {'FAILED':<12}")
                continue
            
            # ë©”íŠ¸ë¦­ ì¶”ì¶œ
            fatmax_power = analysis.metabolic_markers.fat_max.power
            mfo = analysis.metabolic_markers.fat_max.mfo
            
            # RÂ² ê³„ì‚° (smoothed vs trend)
            smoothed = analysis.processed_series.smoothed
            trend = analysis.processed_series.trend
            
            # RÂ² ì¶”ì • (trendê°€ smoothedë¥¼ ì–¼ë§ˆë‚˜ ì˜ ê·¼ì‚¬í•˜ëŠ”ê°€)
            smoothed_fat = np.array([p.fat_oxidation for p in smoothed if p.fat_oxidation is not None])
            
            if len(smoothed_fat) > 0 and len(trend) > 0:
                # Trendë¥¼ smoothed powerì— ë³´ê°„
                trend_powers = [p.power for p in trend]
                trend_fat = [p.fat_oxidation for p in trend if p.fat_oxidation is not None]
                
                # ê°„ë‹¨í•œ ë§¤ì¹­ (ê°€ì¥ ê°€ê¹Œìš´ trend ê°’ ì‚¬ìš©)
                matched_trend = []
                for sp in smoothed:
                    if sp.fat_oxidation is None:
                        continue
                    closest_idx = min(range(len(trend_powers)), 
                                    key=lambda i: abs(trend_powers[i] - sp.power))
                    if trend[closest_idx].fat_oxidation is not None:
                        matched_trend.append(trend[closest_idx].fat_oxidation)
                    else:
                        matched_trend.append(sp.fat_oxidation)
                
                if len(matched_trend) == len(smoothed_fat):
                    matched_trend = np.array(matched_trend)
                    ss_res = np.sum((smoothed_fat - matched_trend) ** 2)
                    ss_tot = np.sum((smoothed_fat - np.mean(smoothed_fat)) ** 2)
                    r_squared = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0
                else:
                    r_squared = 0
            else:
                r_squared = 0
            
            # í”¼í¬ ì†ì‹¤ (binned vs smoothed)
            binned = analysis.processed_series.binned
            binned_fat = [p.fat_oxidation for p in binned if p.fat_oxidation is not None]
            smoothed_fat_list = [p.fat_oxidation for p in smoothed if p.fat_oxidation is not None]
            
            if binned_fat and smoothed_fat_list:
                peak_loss = (max(binned_fat) - max(smoothed_fat_list)) / max(binned_fat) * 100
            else:
                peak_loss = 0
            
            print(f"{frac:<12.2f} {fatmax_power:<12.0f} {mfo:<12.4f} {r_squared:<8.4f} {peak_loss:<10.1f}")
            
            result = {
                'test': 'loess_frac',
                'loess_frac': frac,
                'bin_size': baseline['bin_size'],
                'agg_method': baseline['agg_method'],
                'fatmax_power': fatmax_power,
                'mfo': mfo,
                'r_squared': r_squared,
                'peak_loss_pct': peak_loss,
                'n_binned': len(binned),
                'n_smoothed': len(smoothed),
                'n_trend': len(trend),
            }
            
            results.append(result)
            
            if frac == baseline['loess_frac']:
                baseline_result = result
        
        print()
        
        # === 2. Bin Size ë¯¼ê°ë„ (loess_frac=0.25, agg=median ê³ ì •) ===
        print("2ï¸âƒ£  Bin Size ë¯¼ê°ë„ ë¶„ì„")
        print("-" * 80)
        print(f"{'Bin Size(W)':<12} {'FatMax(W)':<12} {'MFO(g/min)':<12} {'N bins':<10} {'N rawâ†’bin':<12}")
        print("-" * 80)
        
        for bin_sz in bin_sizes:
            analyzer = MetabolismAnalyzer(
                loess_frac=baseline['loess_frac'],
                bin_size=bin_sz,
                use_median=(baseline['agg_method'] == 'median')
            )
            
            if baseline['agg_method'] != 'median':
                analyzer.config.aggregation_method = baseline['agg_method']
            
            analysis = analyzer.analyze(breath_data)
            
            if not analysis:
                print(f"{bin_sz:<12} {'FAILED':<12}")
                continue
            
            fatmax_power = analysis.metabolic_markers.fat_max.power
            mfo = analysis.metabolic_markers.fat_max.mfo
            
            raw_count = len(analysis.processed_series.raw)
            binned_count = len(analysis.processed_series.binned)
            
            # count í•©ê³„ í™•ì¸ (ë°ì´í„° ë³´ì¡´)
            count_sum = sum(p.count for p in analysis.processed_series.binned if hasattr(p, 'count'))
            
            print(f"{bin_sz:<12} {fatmax_power:<12.0f} {mfo:<12.4f} {binned_count:<10} {raw_count}â†’{count_sum}")
            
            results.append({
                'test': 'bin_size',
                'loess_frac': baseline['loess_frac'],
                'bin_size': bin_sz,
                'agg_method': baseline['agg_method'],
                'fatmax_power': fatmax_power,
                'mfo': mfo,
                'n_raw': raw_count,
                'n_binned': binned_count,
                'count_sum': count_sum,
            })
        
        print()
        
        # === 3. Aggregation Method ë¯¼ê°ë„ (loess_frac=0.25, bin_size=10 ê³ ì •) ===
        print("3ï¸âƒ£  Aggregation Method ë¯¼ê°ë„ ë¶„ì„")
        print("-" * 80)
        print(f"{'Method':<15} {'FatMax(W)':<12} {'MFO(g/min)':<12} {'Note':<30}")
        print("-" * 80)
        
        for agg in agg_methods:
            analyzer = MetabolismAnalyzer(
                loess_frac=baseline['loess_frac'],
                bin_size=baseline['bin_size'],
                use_median=(agg == 'median')
            )
            
            if agg != 'median':
                analyzer.config.aggregation_method = agg
            
            analysis = analyzer.analyze(breath_data)
            
            if not analysis:
                print(f"{agg:<15} {'FAILED':<12}")
                continue
            
            fatmax_power = analysis.metabolic_markers.fat_max.power
            mfo = analysis.metabolic_markers.fat_max.mfo
            
            note = ""
            if agg == 'median':
                note = "Robust to outliers (ê¸°ë³¸ê°’)"
            elif agg == 'mean':
                note = "Sensitive to outliers"
            elif agg == 'trimmed_mean':
                note = "Remove 10% extremes"
            
            print(f"{agg:<15} {fatmax_power:<12.0f} {mfo:<12.4f} {note:<30}")
            
            results.append({
                'test': 'agg_method',
                'loess_frac': baseline['loess_frac'],
                'bin_size': baseline['bin_size'],
                'agg_method': agg,
                'fatmax_power': fatmax_power,
                'mfo': mfo,
            })
        
        print()
        
        # === ê²°ê³¼ ë¶„ì„ ===
        print("="*80)
        print("ë¯¼ê°ë„ ë¶„ì„ ìš”ì•½")
        print("="*80 + "\n")
        
        # DataFrame ë³€í™˜
        df = pd.DataFrame(results)
        
        # 1. LOESS Fraction ì˜í–¥
        loess_results = df[df['test'] == 'loess_frac'].copy()
        if not loess_results.empty:
            print("ğŸ“ˆ LOESS Fraction ì˜í–¥:")
            print(f"   FatMax Power ë³€í™”í­: {loess_results['fatmax_power'].min():.0f}W ~ "
                  f"{loess_results['fatmax_power'].max():.0f}W "
                  f"(Â±{(loess_results['fatmax_power'].max() - loess_results['fatmax_power'].min())/2:.0f}W)")
            print(f"   MFO ë³€í™”í­: {loess_results['mfo'].min():.4f} ~ "
                  f"{loess_results['mfo'].max():.4f} g/min "
                  f"(Â±{(loess_results['mfo'].max() - loess_results['mfo'].min())/2:.4f})")
            
            # ìµœì  ë²”ìœ„ ì¶”ì²œ
            acceptable = loess_results[loess_results['peak_loss_pct'] < 10]
            if not acceptable.empty:
                print(f"   âœ… ê¶Œì¥ ë²”ìœ„ (í”¼í¬ ì†ì‹¤ < 10%): "
                      f"{acceptable['loess_frac'].min():.2f} ~ {acceptable['loess_frac'].max():.2f}")
            
            # RÂ² ê¸°ì¤€ ìµœì ê°’
            best_r2 = loess_results.loc[loess_results['r_squared'].idxmax()]
            print(f"   âœ… ìµœê³  Trend Fit: loess_frac={best_r2['loess_frac']:.2f} (RÂ²={best_r2['r_squared']:.4f})")
            print()
        
        # 2. Bin Size ì˜í–¥
        bin_results = df[df['test'] == 'bin_size'].copy()
        if not bin_results.empty:
            print("ğŸ“Š Bin Size ì˜í–¥:")
            print(f"   FatMax Power ë³€í™”í­: {bin_results['fatmax_power'].min():.0f}W ~ "
                  f"{bin_results['fatmax_power'].max():.0f}W "
                  f"(Â±{(bin_results['fatmax_power'].max() - bin_results['fatmax_power'].min())/2:.0f}W)")
            print(f"   MFO ë³€í™”í­: {bin_results['mfo'].min():.4f} ~ "
                  f"{bin_results['mfo'].max():.4f} g/min")
            
            # Bins ìˆ˜ì™€ í•´ìƒë„ íŠ¸ë ˆì´ë“œì˜¤í”„
            print(f"   í•´ìƒë„: 5W â†’ {bin_results[bin_results['bin_size']==5]['n_binned'].values[0]}ê°œ bins, "
                  f"10W â†’ {bin_results[bin_results['bin_size']==10]['n_binned'].values[0]}ê°œ bins")
            print(f"   âœ… ê¶Œì¥: 10W (í•´ìƒë„ì™€ ì•ˆì •ì„± ê· í˜•)")
            print()
        
        # 3. Aggregation Method ì˜í–¥
        agg_results = df[df['test'] == 'agg_method'].copy()
        if not agg_results.empty:
            print("ğŸ”¢ Aggregation Method ì˜í–¥:")
            print(f"   FatMax Power ë³€í™”í­: {agg_results['fatmax_power'].min():.0f}W ~ "
                  f"{agg_results['fatmax_power'].max():.0f}W")
            print(f"   MFO ë³€í™”í­: {agg_results['mfo'].min():.4f} ~ "
                  f"{agg_results['mfo'].max():.4f} g/min")
            print(f"   âœ… ê¶Œì¥: median (ì´ìƒì¹˜ì— ê°•í•¨, ì¬í˜„ì„± ìš°ìˆ˜)")
            print()
        
        # === ìµœì¢… ê¶Œì¥ì‚¬í•­ ===
        print("="*80)
        print("ìµœì¢… ê¶Œì¥ íŒŒë¼ë¯¸í„°")
        print("="*80)
        print(f"âœ… LOESS Fraction: 0.2 ~ 0.3 (ê¸°ë³¸ê°’: 0.25)")
        print(f"   - 0.15: ë„ˆë¬´ ë‚ ì¹´ë¡œì›€, ë…¸ì´ì¦ˆ ë¯¼ê°")
        print(f"   - 0.25: ê· í˜• (ê¶Œì¥)")
        print(f"   - 0.35+: ê³¼ë„í•œ smoothing, í”¼í¬ ì†ì‹¤")
        print()
        print(f"âœ… Bin Size: 10W (5W~15W í—ˆìš©)")
        print(f"   - 5W: ë†’ì€ í•´ìƒë„, ë…¸ì´ì¦ˆ ë§ìŒ")
        print(f"   - 10W: ê· í˜• (ê¶Œì¥)")
        print(f"   - 20W+: í•´ìƒë„ ë‚®ìŒ, ë””í…Œì¼ ì†ì‹¤")
        print()
        print(f"âœ… Aggregation: median (ê¸°ë³¸ê°’)")
        print(f"   - median: ì´ìƒì¹˜ì— ê°•í•¨ (ê¶Œì¥)")
        print(f"   - mean: ë¹ ë¥´ì§€ë§Œ ì´ìƒì¹˜ ë¯¼ê°")
        print(f"   - trimmed_mean: medianê³¼ ìœ ì‚¬, ê³„ì‚° ë¹„ìš© ì•½ê°„ ë†’ìŒ")
        print()
        
        # CSV ì €ì¥ (ì„ íƒ)
        output_path = os.path.join(os.path.dirname(__file__), 'sensitivity_analysis_results.csv')
        df.to_csv(output_path, index=False)
        print(f"ğŸ“„ ìƒì„¸ ê²°ê³¼ ì €ì¥: {output_path}")


if __name__ == "__main__":
    asyncio.run(run_sensitivity_analysis())
